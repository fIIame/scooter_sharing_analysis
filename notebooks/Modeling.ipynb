{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modeling: Подготовка датасетов для моделей и создание самих моделей",
   "id": "4533c139dcf5131e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Импорт библиотек\n",
    "\n",
    "Импортируем стандартные библиотеки для анализа данных, а также пользовательские функции для визуализации и первичного осмотра данных."
   ],
   "id": "5010cf2b6e0f766d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "try:\n",
    "    from utils.paths import join_path as pj\n",
    "except ImportError:\n",
    "    from scooter_sharing_analysis.utils.paths import join_path as pj"
   ],
   "id": "5ec781cc10f484c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Загрузка очищенных данных\n",
    "\n",
    "Загружаем файл rides_weather_data.csv нормализованный после очистки."
   ],
   "id": "e87b03f5c6265fcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Настраиваем словари с параметрами чтения CSV: путь, кодировка, дата-колонки\n",
    "rides_options = {\n",
    "    \"filepath_or_buffer\": pj(\"data\", \"rides_weather_data.csv\"),\n",
    "    \"encoding\": \"utf-8\",\n",
    "    \"parse_dates\": [\"start_date\", \"end_date\", \"day_timestamp\", \"hour_timestamp\"],\n",
    "}\n",
    "\n",
    "rides_weather_data = pd.read_csv(**rides_options)"
   ],
   "id": "444fd0a24796b744"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Создание факторов для моделей: временные, лаговые, погодные",
   "id": "45579201fc73a5e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1. Создание временных и лаговых факторов",
   "id": "4ddf692341f459f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Группируем данные по часовому ряду, получая спрос за каждый час (demand), добавляет новую колонку: 'hour_of_day'. Делим данные на тестовые и тренировочные с соотношение 1:4, добавляем лаговые колонки: 'lag_1h', 'lag_24h', 'mean_last_24h', 'mean_last_7d'",
   "id": "8cd4ce9ddcef5071"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Группировка данных и получение спроса\n",
    "demand = rides_weather_data.groupby(\"hour_timestamp\").agg({\"id\": \"count\"}).rename(columns={\"id\": \"demand\"}).reset_index()\n",
    "\n",
    "# Добавление новых колонки на основе \"hour_timestamp\"\n",
    "demand[\"hour_of_day\"] = demand[\"hour_timestamp\"].dt.hour\n",
    "\n",
    "# Создание лаговых признаков\n",
    "demand[\"lag_1h\"] = demand[\"demand\"].shift(1)\n",
    "demand[\"lag_24h\"] = demand[\"demand\"].shift(24)\n",
    "demand[\"mean_last_24h\"] = demand[\"lag_1h\"].rolling(24).mean()\n",
    "demand[\"mean_last_7d\"] = demand[\"lag_1h\"].rolling(24 * 7).mean()\n",
    "\n",
    "# Удаление строк с Nan значениями в лагах\n",
    "demand = demand.dropna()\n",
    "\n",
    "# Разбиение данных на тестувую и тренировочную части\n",
    "X_demand_train, X_demand_test, Y_demand_train, Y_demand_test = train_test_split(demand, demand[\"demand\"], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Вывод первой 1000 строк\n",
    "X_demand_train.head(1000)\n"
   ],
   "id": "76bad3ff8ed2d74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2. OHE кодирование категориальных признаков: start_location, promo",
   "id": "94472c75804cd102"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Создаем модель OHE для кодирования категориальных признаков \"start_location\", \"promo\", получаем имена будущих колонок для датафрейма с закодированными данными, на основе закодированных данных и имен колонок создаем новый датафрейм, который объединяем по оси 1 с начальным датафреймом предварительно удалив уже ненужные категориальные признаки \"start_location\", \"promo\"",
   "id": "b46bcfdfa8b72deb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Создание OHE модели с заданными параметрами\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "\n",
    "# Название колонок с категориальными признаками\n",
    "column_names = [\"start_location\", \"promo\"]\n",
    "\n",
    "# Кодирование категориальных признаков на основе модели\n",
    "encoded_array = encoder.fit_transform(rides_weather_data[column_names])\n",
    "\n",
    "# Получение названий колонок для будущего датафрейма\n",
    "feat_names = encoder.get_feature_names_out(column_names)\n",
    "\n",
    "# Создание датафрейма с закодированными признаками\n",
    "encoded_data = pd.DataFrame(encoded_array, columns=feat_names)\n",
    "\n",
    "# Объединение датафреймов по 1 оси\n",
    "encoded_rides_weather_data = pd.concat([rides_weather_data.drop(columns=column_names, axis=1), encoded_data], axis=1)\n",
    "\n",
    "# Вывод получившегося датафрейма\n",
    "encoded_rides_weather_data"
   ],
   "id": "4ec177eda3cc3832"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
